{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286d65a0-7ffe-4bd8-a40e-b10f1d6fe32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# text to write to a local file\n",
    "# taken from https://www.theverge.com/2023/3/14/23639313/google-ai-language-model-palm-api-challenge-openai\n",
    "text = \"\"\"Google opens up its AI language model PaLM to challenge OpenAI and GPT-3\n",
    "Google is offering developers access to one of its most advanced AI language models: PaLM.\n",
    "The search giant is launching an API for PaLM alongside a number of AI enterprise tools\n",
    "it says will help businesses “generate text, images, code, videos, audio, and more from\n",
    "simple natural language prompts.”\n",
    "\n",
    "PaLM is a large language model, or LLM, similar to the GPT series created by OpenAI or\n",
    "Meta’s LLaMA family of models. Google first announced PaLM in April 2022. Like other LLMs,\n",
    "PaLM is a flexible system that can potentially carry out all sorts of text generation and\n",
    "editing tasks. You could train PaLM to be a conversational chatbot like ChatGPT, for\n",
    "example, or you could use it for tasks like summarizing text or even writing code.\n",
    "(It’s similar to features Google also announced today for its Workspace apps like Google\n",
    "Docs and Gmail.)\n",
    "\"\"\"\n",
    "\n",
    "# write text to local file\n",
    "with open(\"my_file.txt\", \"w\") as file:\n",
    "    file.write(text)\n",
    "\n",
    "# use TextLoader to load text from local file\n",
    "loader = TextLoader(\"my_file.txt\")\n",
    "docs_from_file = loader.load()\n",
    "\n",
    "print(len(docs_from_file))\n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0767861f-f05c-4f11-8b4c-cdab873c7174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 373, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# create a text splitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "\n",
    "# split documents into chunks\n",
    "docs = text_splitter.split_documents(docs_from_file)\n",
    "\n",
    "print(len(docs))\n",
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d4a32a-8e3a-4286-a5f8-b1a60ac565a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_71636\\1611826015.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "C:\\Users\\akash\\anaconda3\\envs\\Project_1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd62af2-7caf-4063-b6e0-e559d343ebc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\anaconda3\\envs\\Project_1\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.1.6) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://akashghanathey/langchain_course_indexers_retrievers already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import DeepLake\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"keys.env\") \n",
    "ACTIVELOOP_TOKEN= os.getenv(\"ACTIVELOOP_TOKEN\")\n",
    "# Before executing the following code, make sure to have your\n",
    "# Activeloop key saved in the “ACTIVELOOP_TOKEN” environment variable.\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"akashghanathey\"\n",
    "my_activeloop_dataset_name = \"langchain_course_indexers_retrievers\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings,read_only=True)\n",
    "\n",
    "# add documents to our Deep Lake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab784f71-826b-4ba5-bde9-62b25bc6b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913858ce-700e-42ab-865a-ef3e056ebfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.callbacks.base import BaseCallbackManager\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "\n",
    "callback_manager = BaseCallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = GPT4All(\n",
    "    model=\"C:\\\\Users\\\\akash\\\\OneDrive\\\\Documents\\\\GPT4ALL\\\\Meta-Llama-3-8B-Instruct.Q4_0.gguf\",\n",
    "    callbacks=callback_manager,\n",
    "    verbose=False,\n",
    "    device=\"gpu\"  # Use lowercase and correct parameter name\n",
    ")\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\tbase_compressor=compressor,\n",
    "\tbase_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39c4d05-cb06-4eb9-af8c-37ade691a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\AppData\\Local\\Temp\\ipykernel_71636\\3710182599.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = compression_retriever.get_relevant_documents(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "1. Google opens up its AI language model PaLM to challenge OpenAI and GPT-3.\n",
      "2. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.” \n",
      "NO_OUTPUT\n",
      "> Answer: Google is opening up its AI language model PaLM to challenge OpenAI and GPT-3. It's launching an API for PaLM alongside other AI enterprise tools that will help businesses generate various types of content from simple text prompts.\n",
      ">\n",
      "*AS IS*\n",
      "Extracted relevant parts:\n",
      "1. Google opens up its AI language model PaLM to challenge OpenAI and GPT-3.\n",
      "2. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.” \n",
      "NO_OUTPUT\n",
      "> Answer: Google is opening up its AI language model PaLM to challenge OpenAI and GPT-3. It's launching an API for PaLM alongside other AI enterprise tools that will help businesses generate various types of content from simple text prompts.\n",
      ">\n",
      "*AS IS*\n",
      " \n",
      "NO_OUTPUT (since there is no direct relevance)  # NO_OUTPUT\n",
      "\n",
      "Note that the context does not directly address how Google's PaLM will affect OpenAI. Therefore, we cannot extract any part of the context as being relevant to answer this question. The extracted output remains `NO_OUTPUT`.1. Google opens up its AI language model PaLM to challenge OpenAI and GPT-3.\n",
      "2. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.” \n",
      "NO_OUTPUT\n",
      "> Answer: Google is opening up its AI language model PaLM to challenge OpenAI and GPT-3. It's launching an API for PaLM alongside other AI enterprise tools that will help businesses generate various types of content from simple text prompts.\n",
      ">\n",
      "*AS IS*\n",
      "Extracted relevant parts:\n",
      "1. Google opens up its AI language model PaLM to challenge OpenAI and GPT-3.\n",
      "2. The search giant is launching an API for PaLM alongside a number of AI enterprise tools it says will help businesses “generate text, images, code, videos, audio, and more from simple natural language prompts.” \n",
      "NO_OUTPUT\n",
      "> Answer: Google is opening up its AI language model PaLM to challenge OpenAI and GPT-3. It's launching an API for PaLM alongside other AI enterprise tools that will help businesses generate various types of content from simple text prompts.\n",
      ">\n",
      "*AS IS*\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = compression_retriever.get_relevant_documents(\n",
    "\t\"what is google doing how will it effect openai\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e63f82-5f10-44b5-8b50-a89c152daeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akash\\anaconda3\\envs\\Project_1\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc879d1-96a5-4e6f-bd60-5aae06cf93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e25f7feb-aa9b-4154-849c-b5d3c8a4ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_engine=ChatOllama(\n",
    "    model=\"deepseek-r1:14b\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "\n",
    "    temperature=0.3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76808c27-4bbf-45ab-9c58-6affa1d0b1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
